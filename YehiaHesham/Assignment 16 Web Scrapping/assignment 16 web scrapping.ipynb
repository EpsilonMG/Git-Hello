{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, date \n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "## ---------\n",
    "### Scrap the USD To EGP Exchange rate from this website\n",
    "### https://www.exchangerates.org.uk/Dollars-to-Egyptian-Pounds-currency-conversion-page.html\n",
    "### and then use it to make a software that takes amount of USD Dollars from the user and calculate how much will it cost in EGP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rate():\n",
    "    response = requests.request('GET','https://www.exchangerates.org.uk/Dollars-to-Egyptian-Pounds-currency-conversion-page.html')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    rate = soup.find('span',attrs={'id':'shd2b;'})\n",
    "    rate = rate.get_text()\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usd_to_egp():\n",
    "    rate = update_rate()\n",
    "    print(\"Current rate :\", rate)\n",
    "    usd = float(input(\"amount in usd:\"))\n",
    "    egp = usd * float(rate)\n",
    "    print(\"amount in egp=>\",egp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current rate : 15.7204\n",
      "amount in usd:10\n",
      "amount in egp=> 157.204\n"
     ]
    }
   ],
   "source": [
    "usd_to_egp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "## ---------\n",
    "### Scrap the weather temperature, humidity, visibility, air pressure, wind speed, datetime data from this website\n",
    "### https://eg.freemeteo.com/weather/cairo/current-weather/location/?gid=360630&language=english&country=egypt\n",
    "### for 10 times one read in a minute (so basicly the process takes 10 minutes)\n",
    "### and put them into a CSV & Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_weather_data():\n",
    "    response = requests.request('GET','https://eg.freemeteo.com/weather/cairo/current-weather/location/?gid=360630&language=english&country=egypt')\n",
    "    soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "    temp = soup.find('div',attrs={'class':'temp'}).get_text()\n",
    "    stats = soup.find('div',attrs={'class':'stats'}).get_text().strip().split(\"        \")\n",
    "    humidity = stats[1][:-5].strip()\n",
    "    visibility = stats[3][3:-5].strip()\n",
    "    pressure = stats[5]\n",
    "    wind_speed = soup.find('div',attrs={'class':'wind'}).find('b').get_text().strip() + ' Km/h'\n",
    "    \n",
    "    #system time\n",
    "    now = datetime.now().strftime(\"%H:%M:%S\") \n",
    "    today = date.today().strftime(\"%d/%m/%Y\")\n",
    "    system_datetime = now + \" \" + today\n",
    "    \n",
    "    #last reported time\n",
    "    latest_report =\" \".join( soup.find('div',attrs={'class':'last-renew'}).get_text().split(\"(\")[-2].split(\"        \")[-1].split(\" \")[-2:])\n",
    "    \n",
    "    return {'temp': temp,'humidity': humidity, 'visibility': visibility, 'pressure': pressure,\n",
    "           'wind_speed' : wind_speed, 'system_datetime' : system_datetime, 'latest_report' : latest_report}\n",
    "#     return latest_report\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temp': '25°C',\n",
       " 'humidity': '51%',\n",
       " 'visibility': '10000m',\n",
       " 'pressure': '1018.0mbScattered Clouds at 760m',\n",
       " 'wind_speed': '20 Km/h',\n",
       " 'system_datetime': '20:37:38 18/10/2021',\n",
       " 'latest_report': '37m ago'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_data_x10():\n",
    "    with open('assignment 16 task 2 weather data web scrapping.csv','w',encoding = 'utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames = ['temp' , 'humidity' , 'visibility' , 'pressure', 'wind_speed' \n",
    "                                                  , 'system_datetime' , 'latest_report'])\n",
    "        writer.writeheader()\n",
    "        for i in range(1,11):\n",
    "            weather_data = collect_weather_data()\n",
    "            writer.writerow(weather_data)\n",
    "            print(f'Data {i}:',weather_data,'\\n')\n",
    "            #time.sleep(5) #60 but we're all busy xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 1: {'temp': '25°C', 'humidity': '51%', 'visibility': '10000m', 'pressure': '1018.0mbScattered Clouds at 760m', 'wind_speed': '20 Km/h', 'system_datetime': '20:38:07 18/10/2021', 'latest_report': '38m ago'} \n",
      "\n",
      "Data 2: {'temp': '25°C', 'humidity': '51%', 'visibility': '10000m', 'pressure': '1018.0mbScattered Clouds at 760m', 'wind_speed': '20 Km/h', 'system_datetime': '20:38:10 18/10/2021', 'latest_report': '38m ago'} \n",
      "\n",
      "Data 3: {'temp': '25°C', 'humidity': '51%', 'visibility': '10000m', 'pressure': '1018.0mbScattered Clouds at 760m', 'wind_speed': '20 Km/h', 'system_datetime': '20:38:12 18/10/2021', 'latest_report': '38m ago'} \n",
      "\n",
      "Data 4: {'temp': '25°C', 'humidity': '51%', 'visibility': '10000m', 'pressure': '1018.0mbScattered Clouds at 760m', 'wind_speed': '20 Km/h', 'system_datetime': '20:38:13 18/10/2021', 'latest_report': '38m ago'} \n",
      "\n",
      "Data 5: {'temp': '25°C', 'humidity': '51%', 'visibility': '10000m', 'pressure': '1018.0mbScattered Clouds at 760m', 'wind_speed': '20 Km/h', 'system_datetime': '20:38:16 18/10/2021', 'latest_report': '38m ago'} \n",
      "\n",
      "Data 6: {'temp': '25°C', 'humidity': '51%', 'visibility': '10000m', 'pressure': '1018.0mbScattered Clouds at 760m', 'wind_speed': '20 Km/h', 'system_datetime': '20:38:17 18/10/2021', 'latest_report': '38m ago'} \n",
      "\n",
      "Data 7: {'temp': '25°C', 'humidity': '51%', 'visibility': '10000m', 'pressure': '1018.0mbScattered Clouds at 760m', 'wind_speed': '20 Km/h', 'system_datetime': '20:38:18 18/10/2021', 'latest_report': '38m ago'} \n",
      "\n",
      "Data 8: {'temp': '25°C', 'humidity': '51%', 'visibility': '10000m', 'pressure': '1018.0mbScattered Clouds at 760m', 'wind_speed': '20 Km/h', 'system_datetime': '20:38:20 18/10/2021', 'latest_report': '38m ago'} \n",
      "\n",
      "Data 9: {'temp': '25°C', 'humidity': '51%', 'visibility': '10000m', 'pressure': '1018.0mbScattered Clouds at 760m', 'wind_speed': '20 Km/h', 'system_datetime': '20:38:21 18/10/2021', 'latest_report': '38m ago'} \n",
      "\n",
      "Data 10: {'temp': '25°C', 'humidity': '51%', 'visibility': '10000m', 'pressure': '1018.0mbScattered Clouds at 760m', 'wind_speed': '20 Km/h', 'system_datetime': '20:38:22 18/10/2021', 'latest_report': '38m ago'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_data_x10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>visibility</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>system_datetime</th>\n",
       "      <th>latest_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25°C</td>\n",
       "      <td>51%</td>\n",
       "      <td>10000m</td>\n",
       "      <td>1018.0mbScattered Clouds at 760m</td>\n",
       "      <td>20 Km/h</td>\n",
       "      <td>20:38:07 18/10/2021</td>\n",
       "      <td>38m ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25°C</td>\n",
       "      <td>51%</td>\n",
       "      <td>10000m</td>\n",
       "      <td>1018.0mbScattered Clouds at 760m</td>\n",
       "      <td>20 Km/h</td>\n",
       "      <td>20:38:10 18/10/2021</td>\n",
       "      <td>38m ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25°C</td>\n",
       "      <td>51%</td>\n",
       "      <td>10000m</td>\n",
       "      <td>1018.0mbScattered Clouds at 760m</td>\n",
       "      <td>20 Km/h</td>\n",
       "      <td>20:38:12 18/10/2021</td>\n",
       "      <td>38m ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25°C</td>\n",
       "      <td>51%</td>\n",
       "      <td>10000m</td>\n",
       "      <td>1018.0mbScattered Clouds at 760m</td>\n",
       "      <td>20 Km/h</td>\n",
       "      <td>20:38:13 18/10/2021</td>\n",
       "      <td>38m ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25°C</td>\n",
       "      <td>51%</td>\n",
       "      <td>10000m</td>\n",
       "      <td>1018.0mbScattered Clouds at 760m</td>\n",
       "      <td>20 Km/h</td>\n",
       "      <td>20:38:16 18/10/2021</td>\n",
       "      <td>38m ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25°C</td>\n",
       "      <td>51%</td>\n",
       "      <td>10000m</td>\n",
       "      <td>1018.0mbScattered Clouds at 760m</td>\n",
       "      <td>20 Km/h</td>\n",
       "      <td>20:38:17 18/10/2021</td>\n",
       "      <td>38m ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25°C</td>\n",
       "      <td>51%</td>\n",
       "      <td>10000m</td>\n",
       "      <td>1018.0mbScattered Clouds at 760m</td>\n",
       "      <td>20 Km/h</td>\n",
       "      <td>20:38:18 18/10/2021</td>\n",
       "      <td>38m ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25°C</td>\n",
       "      <td>51%</td>\n",
       "      <td>10000m</td>\n",
       "      <td>1018.0mbScattered Clouds at 760m</td>\n",
       "      <td>20 Km/h</td>\n",
       "      <td>20:38:20 18/10/2021</td>\n",
       "      <td>38m ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25°C</td>\n",
       "      <td>51%</td>\n",
       "      <td>10000m</td>\n",
       "      <td>1018.0mbScattered Clouds at 760m</td>\n",
       "      <td>20 Km/h</td>\n",
       "      <td>20:38:21 18/10/2021</td>\n",
       "      <td>38m ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25°C</td>\n",
       "      <td>51%</td>\n",
       "      <td>10000m</td>\n",
       "      <td>1018.0mbScattered Clouds at 760m</td>\n",
       "      <td>20 Km/h</td>\n",
       "      <td>20:38:22 18/10/2021</td>\n",
       "      <td>38m ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp humidity visibility                          pressure wind_speed  \\\n",
       "0  25°C      51%     10000m  1018.0mbScattered Clouds at 760m    20 Km/h   \n",
       "1  25°C      51%     10000m  1018.0mbScattered Clouds at 760m    20 Km/h   \n",
       "2  25°C      51%     10000m  1018.0mbScattered Clouds at 760m    20 Km/h   \n",
       "3  25°C      51%     10000m  1018.0mbScattered Clouds at 760m    20 Km/h   \n",
       "4  25°C      51%     10000m  1018.0mbScattered Clouds at 760m    20 Km/h   \n",
       "5  25°C      51%     10000m  1018.0mbScattered Clouds at 760m    20 Km/h   \n",
       "6  25°C      51%     10000m  1018.0mbScattered Clouds at 760m    20 Km/h   \n",
       "7  25°C      51%     10000m  1018.0mbScattered Clouds at 760m    20 Km/h   \n",
       "8  25°C      51%     10000m  1018.0mbScattered Clouds at 760m    20 Km/h   \n",
       "9  25°C      51%     10000m  1018.0mbScattered Clouds at 760m    20 Km/h   \n",
       "\n",
       "       system_datetime latest_report  \n",
       "0  20:38:07 18/10/2021       38m ago  \n",
       "1  20:38:10 18/10/2021       38m ago  \n",
       "2  20:38:12 18/10/2021       38m ago  \n",
       "3  20:38:13 18/10/2021       38m ago  \n",
       "4  20:38:16 18/10/2021       38m ago  \n",
       "5  20:38:17 18/10/2021       38m ago  \n",
       "6  20:38:18 18/10/2021       38m ago  \n",
       "7  20:38:20 18/10/2021       38m ago  \n",
       "8  20:38:21 18/10/2021       38m ago  \n",
       "9  20:38:22 18/10/2021       38m ago  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment 16 task 2 weather data web scrapping.csv') \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "## ---------\n",
    "### Scrap the books (name, price, rate) for each category and put them into a CSV & Excel file\n",
    "### https://books.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.request('GET',\"https://books.toscrape.com/\")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### original attempt, scrapped as it didn't account for multiple pages per category ###\n",
    "#==============================================================================================#\n",
    "# #def scrape_categories():\n",
    "    \n",
    "# all_categories = soup.find('div',attrs = { 'class':'side_categories'}).find('ul').find_all('a')\n",
    "# categories_names = []\n",
    "# categories_links = []\n",
    "# categories = []\n",
    "\n",
    "# for category in all_categories:\n",
    "#     categories_names.append(category.get_text().strip())\n",
    "#     categories_links.append(category.get('href'))\n",
    "\n",
    "# for index in range(len(all_categories)):\n",
    "#     categories.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index]))\n",
    "\n",
    "# #return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some random commands for testing\n",
    "#==============================================================================================#\n",
    "# category_response = requests.request('GET',categories[0][1])\n",
    "# #categories[0][1]\n",
    "# category_soup = BeautifulSoup(category_response.content,'html.parser')\n",
    "# #category_soup\n",
    "# next_btn = category_soup.find('li',attrs={'class':'current'})#.get_text().split()[-1]\n",
    "# next_btn.get_text().split()[-1]\n",
    "# print(\"test:\", next_btn == None)\n",
    "# int(next_btn.get_text().split()[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt 2 \n",
    "def scrape_pages():\n",
    "    \n",
    "    all_categories = soup.find('div',attrs = { 'class':'side_categories'}).find('ul').find_all('a')\n",
    "    \n",
    "    categories_names = []       #all main categories \n",
    "    categories_main_pages = []  #index/main page of each category '../../index.html'\n",
    "    categories_links = []       #all links/directories for all categories' main page\n",
    "    all_pages = []   #all pages' data (category,link)\n",
    "    \n",
    "        #save each category's name & link to lists 'names' and 'links'\n",
    "    for category in all_categories:\n",
    "        categories_names.append(category.get_text().strip())\n",
    "        categories_links.append(category.get('href'))\n",
    "    \n",
    "        #loop by number of categories\n",
    "    for index in range(len(all_categories)):\n",
    "        \n",
    "            #save category's main page data to list 'main_pages'\n",
    "        categories_main_pages.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index]))\n",
    "        \n",
    "            #detect 'next' button in category's main page\n",
    "        category_response = requests.request('GET',categories_main_pages[index][1])\n",
    "        category_soup = BeautifulSoup(category_response.content,'html.parser')\n",
    "        next_btn = category_soup.find('li',attrs={'class':'current'})\n",
    "        \n",
    "            #if there is no \"next\" button (category has single page), add main page data to list 'all_pages' \n",
    "        if next_btn == None:   \n",
    "            all_pages.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index]))\n",
    "            \n",
    "        else:\n",
    "                #detect how many pages are there for the category \n",
    "            count = int(next_btn.get_text().split()[-1])\n",
    "            \n",
    "                #loop by number of pages and add each page's data to list 'all_pages'\n",
    "            for i in range(1,count+1):\n",
    "                all_pages.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index][:-10]+f'page-{i}.html'))\n",
    "                \n",
    "    return all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books(all_pages):\n",
    "    \n",
    "    book_entries = [] #each book's data (category, name, price, rating)\n",
    "    \n",
    "        #loop by each page in , find each book's information and save it in list 'books' \n",
    "    for category in range(50,len(all_pages)):     #skips pages with category 'Books' (from 0 to 49) as it contains all other books\n",
    "        \n",
    "        response = requests.request('GET',all_pages[category][1])\n",
    "        soup = BeautifulSoup(response.content,'html.parser')\n",
    "        books = soup.find_all('article',attrs={'class':'product_pod'}) #finds all the books in the page and puts them in a list \n",
    "        \n",
    "            #loop by number of books found in page\n",
    "        for book in range(len(books)):\n",
    "            \n",
    "                #collect book info\n",
    "            cat = all_pages[category][0]\n",
    "            name = books[book].find('h3').find('a').get('title')\n",
    "            price = books[book].find('p',attrs={'class':'price_color'}).get_text()[1:] + \" £\"\n",
    "            rating = books[book].find('p').get('class')[1] + \" star(s)\"\n",
    "            \n",
    "                #append book info to list 'book_entries'\n",
    "            book_entries.append({\"cat\": cat, \"name\": name, \"price\":price, \"rating\": rating})\n",
    "            \n",
    "    return book_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_the_website():\n",
    "    \n",
    "    print(\"scrapping website pages, please wait...\")\n",
    "    pages = scrape_pages()\n",
    "    \n",
    "    print(\"scraping website pages complete, scrapping book data...\")\n",
    "    book_data = scrape_books(pages)\n",
    "    \n",
    "    print(\"scraping book data complete, writing file...\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    with open('assignment 16 task 3 books to scrape web scrapping.csv','w') as f:\n",
    "        writer = csv.DictWriter(f,fieldnames = ['cat','name','price','rating'])\n",
    "        writer.writeheader()\n",
    "        for i in range(len(book_data)):\n",
    "            writer.writerow(book_data[i])     \n",
    "    print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping website pages, please wait...\n",
      "scraping website pages complete, scrapping book data...\n",
      "scraping book data complete, writing file...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "scrape_the_website()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('assignment 16 task 3 books to scrape web scrapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>Poetry</td>\n",
       "      <td>The Crossover</td>\n",
       "      <td>38.77 �</td>\n",
       "      <td>Four star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>Autobiography</td>\n",
       "      <td>M Train</td>\n",
       "      <td>27.18 �</td>\n",
       "      <td>One star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Sequential Art</td>\n",
       "      <td>The Demon Prince of Momochi House, Vol. 4 (The...</td>\n",
       "      <td>27.88 �</td>\n",
       "      <td>Two star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>The 14th Colony (Cotton Malone #11)</td>\n",
       "      <td>39.24 �</td>\n",
       "      <td>One star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>Poetry</td>\n",
       "      <td>The Collected Poems of W.B. Yeats (The Collect...</td>\n",
       "      <td>15.42 �</td>\n",
       "      <td>Five star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Add a comment</td>\n",
       "      <td>Fun Home: A Family Tragicomic</td>\n",
       "      <td>56.59 �</td>\n",
       "      <td>Four star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Fiction</td>\n",
       "      <td>Daredevils</td>\n",
       "      <td>16.34 �</td>\n",
       "      <td>Three star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Young Adult</td>\n",
       "      <td>Walk the Edge (Thunder Road #2)</td>\n",
       "      <td>32.36 �</td>\n",
       "      <td>Three star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Travel</td>\n",
       "      <td>See America: A Celebration of Our National Par...</td>\n",
       "      <td>48.87 �</td>\n",
       "      <td>Three star(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Talking to Girls About Duran Duran: One Young ...</td>\n",
       "      <td>25.15 �</td>\n",
       "      <td>Four star(s)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cat                                               name  \\\n",
       "828          Poetry                                      The Crossover   \n",
       "848   Autobiography                                            M Train   \n",
       "114  Sequential Art  The Demon Prince of Momochi House, Vol. 4 (The...   \n",
       "961        Thriller                The 14th Colony (Cotton Malone #11)   \n",
       "827          Poetry  The Collected Poems of W.B. Yeats (The Collect...   \n",
       "660   Add a comment                      Fun Home: A Family Tragicomic   \n",
       "256         Fiction                                         Daredevils   \n",
       "783     Young Adult                    Walk the Edge (Thunder Road #2)   \n",
       "2            Travel  See America: A Celebration of Our National Par...   \n",
       "396      Nonfiction  Talking to Girls About Duran Duran: One Young ...   \n",
       "\n",
       "       price         rating  \n",
       "828  38.77 �   Four star(s)  \n",
       "848  27.18 �    One star(s)  \n",
       "114  27.88 �    Two star(s)  \n",
       "961  39.24 �    One star(s)  \n",
       "827  15.42 �   Five star(s)  \n",
       "660  56.59 �   Four star(s)  \n",
       "256  16.34 �  Three star(s)  \n",
       "783  32.36 �  Three star(s)  \n",
       "2    48.87 �  Three star(s)  \n",
       "396  25.15 �   Four star(s)  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)    #1000 Books"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
