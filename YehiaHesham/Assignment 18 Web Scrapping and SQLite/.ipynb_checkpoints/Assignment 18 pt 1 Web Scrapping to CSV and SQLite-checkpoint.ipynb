{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774c5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, date \n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216cec9f",
   "metadata": {},
   "source": [
    "### Scrap the books (name, price, rate) for each category and put them into a CSV & Excel file\n",
    "### https://books.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eef10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.request('GET',\"https://books.toscrape.com/\")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee0c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### original attempt, scrapped as it didn't account for multiple pages per category ###\n",
    "#==============================================================================================#\n",
    "# #def scrape_categories():\n",
    "    \n",
    "# all_categories = soup.find('div',attrs = { 'class':'side_categories'}).find('ul').find_all('a')\n",
    "# categories_names = []\n",
    "# categories_links = []\n",
    "# categories = []\n",
    "\n",
    "# for category in all_categories:\n",
    "#     categories_names.append(category.get_text().strip())\n",
    "#     categories_links.append(category.get('href'))\n",
    "\n",
    "# for index in range(len(all_categories)):\n",
    "#     categories.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index]))\n",
    "\n",
    "# #return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc4db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt 2 \n",
    "def scrape_pages():\n",
    "    \n",
    "    all_categories = soup.find('div',attrs = { 'class':'side_categories'}).find('ul').find_all('a')\n",
    "    \n",
    "    categories_names = []       #all main categories \n",
    "    categories_main_pages = []  #index/main page of each category '../../index.html'\n",
    "    categories_links = []       #all links/directories for all categories' main page\n",
    "    all_pages = []   #all pages' data (category,link)\n",
    "    \n",
    "        #save each category's name & link to lists 'names' and 'links'\n",
    "    for category in all_categories:\n",
    "        categories_names.append(category.get_text().strip())\n",
    "        categories_links.append(category.get('href'))\n",
    "    \n",
    "        #loop by number of categories\n",
    "    for index in range(len(all_categories)):\n",
    "        \n",
    "            #save category's main page data to list 'main_pages'\n",
    "        categories_main_pages.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index]))\n",
    "        \n",
    "            #detect 'next' button in category's main page\n",
    "        category_response = requests.request('GET',categories_main_pages[index][1])\n",
    "        category_soup = BeautifulSoup(category_response.content,'html.parser')\n",
    "        next_btn = category_soup.find('li',attrs={'class':'current'})\n",
    "        \n",
    "            #if there is no \"next\" button (category has single page), add main page data to list 'all_pages' \n",
    "        if next_btn == None:   \n",
    "            all_pages.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index]))\n",
    "            \n",
    "        else:\n",
    "                #detect how many pages are there for the category \n",
    "            count = int(next_btn.get_text().split()[-1])\n",
    "            \n",
    "                #loop by number of pages and add each page's data to list 'all_pages'\n",
    "            for i in range(1,count+1):\n",
    "                all_pages.append((categories_names[index] , 'https://books.toscrape.com/'+categories_links[index][:-10]+f'page-{i}.html'))\n",
    "                \n",
    "    return all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726fc9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books(all_pages):\n",
    "    \n",
    "    book_entries = [] #each book's data (category, name, price, rating)\n",
    "    rating_dict = {\"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4, \"Five\": 5}\n",
    "    \n",
    "        #loop by each page in , find each book's information and save it in list 'books' \n",
    "    for category in range(50,len(all_pages)):     #skips pages with category 'Books' (from 0 to 49) as it contains all other books\n",
    "        \n",
    "        response = requests.request('GET',all_pages[category][1])\n",
    "        soup = BeautifulSoup(response.content,'html.parser')\n",
    "        books = soup.find_all('article',attrs={'class':'product_pod'}) #finds all the books in the page and puts them in a list \n",
    "        \n",
    "            #loop by number of books found in page\n",
    "        for book in range(len(books)):\n",
    "            \n",
    "                #collect book info\n",
    "            cat = all_pages[category][0]\n",
    "            name = books[book].find('h3').find('a').get('title')\n",
    "            price = float((books[book].find('p',attrs={'class':'price_color'}).get_text()[1:]).strip())\n",
    "            rating = rating_dict[(books[book].find('p').get('class')[1]).strip()]\n",
    "            \n",
    "                #append book info to list 'book_entries'\n",
    "            book_entries.append({\"category\": cat, \"name\": name, \"price in £\":price, \"rating star(s)\": rating})\n",
    "            \n",
    "    return book_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3356c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_the_website():\n",
    "    print(\"scrapping website pages, please wait...\")\n",
    "    pages = scrape_pages()\n",
    "    \n",
    "    print(\"scraping website pages complete, scrapping book data...\")\n",
    "    book_data = scrape_books(pages)\n",
    "    \n",
    "    print(\"scraping book data complete, writing data in csv file...\")\n",
    "    #time.sleep(2)\n",
    "    \n",
    "    #Write books in csv file ==========================\n",
    "    with open('books to scrape web scrapping.csv','w') as f:\n",
    "        writer = csv.DictWriter(f,fieldnames = ['category','name','price in £','rating star(s)'])\n",
    "        writer.writeheader()\n",
    "        for i in range(len(book_data)):\n",
    "            writer.writerow(book_data[i])     \n",
    "    print(\"writing csv file complete, writing categories in database SQLite...\")\n",
    "    \n",
    "    #collect categories ==========================\n",
    "    categories = []\n",
    "    for page in book_data:\n",
    "        categories.append(page['category'])\n",
    "    categories = list(set(categories))\n",
    "    \n",
    "    #Saving categories in a SQLite DataBase ==========================\n",
    "    connection = sqlite3.connect('Books to scrape.db')\n",
    "    sql = \"INSERT INTO Categories (Cat_Name) VALUES (?)\"\n",
    "    for cat in categories:\n",
    "        data = [cat]\n",
    "        cursor = connection.execute(sql,data)\n",
    "        connection.commit()\n",
    "    connection.close()\n",
    "    print(\"writing Categories complete, writing Books in database SQLite...\")\n",
    "        \n",
    "    #Saving books in a SQLite Database ==========================\n",
    "    connection = sqlite3.connect('Books to scrape.db')\n",
    "    sql = \"INSERT INTO Books (Book_Name,Book_Price,Book_Rating,Cat_ID) VALUES ( ? , ? , ? , (SELECT Cat_ID from Categories WHERE Cat_Name = ?))\"\n",
    "    for book in book_data:\n",
    "        data = [book['name'],book['price in £'],book['rating star(s)'],book['category']]\n",
    "        cursor = connection.execute(sql,data)\n",
    "        connection.commit()\n",
    "    connection.close()\n",
    "    print(\"writing Books complete.\")\n",
    "    # ==========================\n",
    "    print(\"Done.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcc24dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Travel',\n",
       " 'Parenting',\n",
       " 'Novels',\n",
       " 'Health',\n",
       " 'Cultural',\n",
       " 'Horror',\n",
       " 'Erotica',\n",
       " 'Music',\n",
       " 'Sports and Games',\n",
       " 'Spirituality',\n",
       " 'Contemporary',\n",
       " 'Suspense',\n",
       " 'Fantasy',\n",
       " 'Historical',\n",
       " 'Religion',\n",
       " 'Politics',\n",
       " 'Young Adult',\n",
       " 'Poetry',\n",
       " 'Crime',\n",
       " 'Academic',\n",
       " 'Art',\n",
       " 'Science Fiction',\n",
       " 'Add a comment',\n",
       " 'Historical Fiction',\n",
       " 'Business',\n",
       " 'Thriller',\n",
       " 'New Adult',\n",
       " 'Short Stories',\n",
       " 'Childrens',\n",
       " 'Mystery',\n",
       " 'Paranormal',\n",
       " 'Nonfiction',\n",
       " 'Psychology',\n",
       " 'Self Help',\n",
       " 'Christian Fiction',\n",
       " 'Food and Drink',\n",
       " 'Romance',\n",
       " 'Philosophy',\n",
       " 'Adult Fiction',\n",
       " 'Biography',\n",
       " 'Womens Fiction',\n",
       " 'Sequential Art',\n",
       " 'Science',\n",
       " 'Christian',\n",
       " 'Autobiography',\n",
       " 'Classics',\n",
       " 'Fiction',\n",
       " 'Default',\n",
       " 'History',\n",
       " 'Humor']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categories = []\n",
    "# for page in book_data:\n",
    "#     categories.append(page['category'])\n",
    "# categories = list(set(categories))\n",
    "# categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69446c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping website pages, please wait...\n",
      "scraping website pages complete, scrapping book data...\n",
      "scraping book data complete, writing data in csv file...\n",
      "writing csv file complete, writing categories in database SQLite...\n",
      "writing Categories complete, writing Books in database SQLite...\n",
      "writing Books complete.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "scrape_the_website()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b006074",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('books to scrape web scrapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8bfc1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>price in �</th>\n",
       "      <th>rating star(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Historical Fiction</td>\n",
       "      <td>Lilac Girls</td>\n",
       "      <td>17.28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>The Past Never Ends</td>\n",
       "      <td>56.50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>The Gunning of America: Business and the Makin...</td>\n",
       "      <td>16.81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>Psychology</td>\n",
       "      <td>The Golden Condom: And Other Essays on Love Lo...</td>\n",
       "      <td>39.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>History</td>\n",
       "      <td>Thomas Jefferson and the Tripoli Pirates: The ...</td>\n",
       "      <td>59.64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Throwing Rocks at the Google Bus: How Growth B...</td>\n",
       "      <td>31.12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Science</td>\n",
       "      <td>Diary of a Citizen Scientist: Chasing Tiger Be...</td>\n",
       "      <td>28.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Historical Fiction</td>\n",
       "      <td>The Marriage of Opposites</td>\n",
       "      <td>28.08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>Young Adult</td>\n",
       "      <td>Future Shock (Future Shock #1)</td>\n",
       "      <td>55.65</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Default</td>\n",
       "      <td>Taking Shots (Assassins #1)</td>\n",
       "      <td>18.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category                                               name  \\\n",
       "52   Historical Fiction                                        Lilac Girls   \n",
       "13              Mystery                                The Past Never Ends   \n",
       "400          Nonfiction  The Gunning of America: Business and the Makin...   \n",
       "841          Psychology  The Golden Condom: And Other Essays on Love Lo...   \n",
       "889             History  Thomas Jefferson and the Tripoli Pirates: The ...   \n",
       "332          Nonfiction  Throwing Rocks at the Google Bus: How Growth B...   \n",
       "803             Science  Diary of a Citizen Scientist: Chasing Tiger Be...   \n",
       "48   Historical Fiction                          The Marriage of Opposites   \n",
       "770         Young Adult                     Future Shock (Future Shock #1)   \n",
       "596             Default                        Taking Shots (Assassins #1)   \n",
       "\n",
       "     price in �  rating star(s)  \n",
       "52        17.28               2  \n",
       "13        56.50               4  \n",
       "400       16.81               4  \n",
       "841       39.43               1  \n",
       "889       59.64               1  \n",
       "332       31.12               3  \n",
       "803       28.41               1  \n",
       "48        28.08               4  \n",
       "770       55.65               5  \n",
       "596       18.88               2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df61094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)    #1000 Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb5d55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"It's Only the Himalayas\", 2, 45.17, 'Travel'),\n",
       " ('Full Moon over Noah’s Ark: An Odyssey to Mount Ararat and Beyond',\n",
       "  4,\n",
       "  49.43,\n",
       "  'Travel'),\n",
       " ('See America: A Celebration of Our National Parks & Treasured Sites',\n",
       "  3,\n",
       "  48.87,\n",
       "  'Travel'),\n",
       " ('Vagabonding: An Uncommon Guide to the Art of Long-Term World Travel',\n",
       "  2,\n",
       "  36.94,\n",
       "  'Travel'),\n",
       " ('Under the Tuscan Sun', 3, 37.33, 'Travel'),\n",
       " ('A Summer In Europe', 2, 44.34, 'Travel'),\n",
       " ('The Great Railway Bazaar', 1, 30.54, 'Travel'),\n",
       " ('A Year in Provence (Provence #1)', 4, 56.88, 'Travel'),\n",
       " ('The Road to Little Dribbling: Adventures of an American in Britain (Notes From a Small Island #2)',\n",
       "  1,\n",
       "  23.21,\n",
       "  'Travel'),\n",
       " ('Neither Here nor There: Travels in Europe', 3, 38.95, 'Travel')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = sqlite3.connect('Books to scrape.db')\n",
    "sql = \"SELECT Books.Book_Name, Books.Book_Rating, Books.Book_Price, Categories.Cat_Name FROM Books INNER JOIN Categories ON Books.Cat_ID = Categories.Cat_ID\"\n",
    "cursor = connection.execute(sql)\n",
    "cursor.fetchmany(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdfef14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"SELECT COUNT(Book_Name) FROM Books\"\n",
    "cursor.execute(sql)\n",
    "cursor.fetchone()    #1000 books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb583ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
